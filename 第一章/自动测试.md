# 单元测试

在开始实现真正的编译器之前，我们还要做最后一个准备工作：单元测试。

在上一节重新组织代码结构的过程中，我就深深体会到自动单元测试的重要性。

如果没有自动单元测试，每次修改后很容易漏掉某个测试例子，一不小心就发现新的代码已经在某个地方出问题了。

即使是现在这么简单的代码结构，但由于Z语言编译器的特色，有6种输出，因此每做一个修改都手动测6种输出是不现实的。

## 选择测试工具

C语言里没有标准的测试框架。

不过还好我使用的构建工具`xmake`提供了简单的测试框架，我研究了一下，发现基本足够Z编译器当前的需求了。

`xmake test`目前主要还是基于可执行文件来测试的，即我们需要写一个测试程序，`xmake`根据配置运行它，根据参数获得结果（返回值或标准输出），然后和配置的预期结果比较。

这和Java里常见的用`@Test`函数来组织用例，用各种`assert`来判断结果的方式不同。

但是这种方式却比较适合编译器的开发，因为编译器的输入和输出通常都是源码，也常常使用文件格式，所以能够直接对比输出或文件才是最合适的办法。

`xmake test`支持：

- 测试执行和结果输出；尤其可以输出`actual`和`expected`的实际值。
- 测试用例可以分组。
- 支持多种测试方式：返回值判定、输出判定等。
- 可以支持同一个测试多种输入参数和输出参数。
- 和编译流程集成，非常方便。

目前只有一个需求并不满足：如果要测试的程序输出的不是字符串，而是一个文件，无法简单配置与预期文件的对比。
这个功能我自己在测试代码中实现了，不过还是希望以后`xmake`可以支持。

## 解释器的测试

解释器的输入是一句代码，输出则是一段字符串（想象一下REPL中每一个读写循环）。

因此解释器的测试非常适合对标准输出进行判定的模式。在`xmake`里，这个模式叫`pass_output`，即测试程序的输入如果与预期输出一致，就能通过测试。

下面是最简单的`hello world`测试的测试配置，这个配置写在工程配置`xmake.lua`里：

```lua
-- 测试的目标名称test_interp
target("test_interp")
    -- 基本配置
    set_kind("binary")
    set_default(false)
    -- 因为解释器功能需要调用源码中的函数，所以需要包含源码目录
    add_includedirs("src")
    add_files("src/*.c")
    -- 但测试文件不需要源码里的main.c
    remove_files("src/main.c")
    -- 而是改用自己的test_interp.c
    add_files("test/test_interp.c")
    -- 用例1：print("Hello, world!")，解释器应当输出"Hello, world!"
    add_tests("pass_output_1", {runargs="print(\"Hello, world!\")", trim_output=true, pass_outputs="Hello, world!"})
    -- 用例2：print("Now!")，解释器应当输出"Now!"
    add_tests("pass_output_2", {runargs="print(\"Now!\")", trim_output=true, pass_outputs="Now!"})
```

`test_interp.c`的内容如下：

```c
#include <stdio.h>
#include "interp.h"

int main(int argc, char** argv) {
    // argv[1]参数是要解释的代码
    if (argc < 2) {
        printf("Error: args: <z code>\n");
        return -1;
    }
    char *code = argv[1];
    // 解释代码，结果会打印到标准输出
    interp(code);
    return 0;
}
```

我们这里调用了解释器的`interp`函数，去解释`print("Hello, world!")`这句代码。
当测试用例改为`print("Now!")`时，解释器的输出也会改变。这就证明了我们的解释器还是懂一点东西的。

## 编译器的测试

编译器的测试和解释器稍有不同：

- 编译器的输入是一个文件名，需要读取文件内容；
- 编译器的输出也是一个文件，即汇编文件。所以不能用输出作比较，而是需要进行文件对比。
- 预期的结果也是一个文件，这时候把预期的内容直接写在测试配置`xmake.lua`里就不太现实了，而是应该存放在一个文件里。
- 编译器在Windows和Linux平台有不同的输出，所以测试用例也应该有两种平台的预期结果。

我们在`test`目录里建立`test_compile.c`，内容如下：

```c
#include <stdio.h>
#include "compiler.h"
#include "util.h"

int main(int argc, char** argv) {
    // 需要两个参数，一个是要编译的文件，例如hello.z；另一个是期望输出的内容，例如hello_expect.s
    if (argc < 3) {
        return -1;
    }
    // 编译文件并输出到app.s或app.asm
    build(argv[1]); // output to app.s/app.asm

    // 将app.s/app.asm与期望输出文件进行比较
    char *expected = argv[2];

#ifdef _WIN32
    return compare_file("app.asm", expected);
#else
    return compare_file("app.s", expected);
#endif
}
```

这个测试文件接收两个参数：

- Z源码文件名，即要编译的对象
- 用来对比的预期输出文件名，例如hello_expected.s

测试文件先调用编译器`build`函数，将源码编译成汇编文件，并输出到`app.s`或`app.asm`里。
再调用`compare_file`函数，将`app.s`或`app.asm`与预期输出文件进行比较。
如果两个文件内容一致，就返回0，否则返回-1。

这个`compare_file`函数是我们自己写的。它的功能是逐个字符对比两个文件，遇到不一致的时候就退出，直到文件末尾。

`xmake.lua`中的测试配置与上一节解释器的测试配置也略有不同：

```lua
target("test_compiler")
    set_kind("binary")
    set_default(false)
    add_includedirs("src")
    add_files("src/*.c")
    remove_files("src/main.c")
    add_files("test/test_compiler.c")
    -- 需要根据操作系统来选择额不同的预期输出文件
    if is_plat("windows") then
        add_tests("expect_file", {rundir = os.projectdir().."/test/hello", runargs = {"hello.z", "hello_expect.asm"}})
    else
        add_tests("expect_file", {rundir = os.projectdir().."/test/hello", runargs = {"hello.z", "hello_expect.s"}})
    end
```

最主要的不同就是`add_tests`的参数。

首先，需要指定`rundir`。

因为这里需要对比文件，且不同操作系统下的预期输出是不一样的（Windows里是`masm64`格式的`.asm`文件；Linux下是`gas`格式的`.s`文件），
所以我们干脆为每一个测试用例单独设置了目录，用来存放两个不同的预期文件，以及测试过程中生成的中间文件和汇编文件。
例如，`hello.z`这个测试文件就放在`test/hello`目录里。对应的预期输出文件也放在这个目录里。

其次，要传入用来对比的预期文件的名称，可以看到，我们在Windows下传入的是`hello_expect.asm`，而在Linux下传入的是`hello_expect.s`。

真正的对比操作是放在`test/test_compiler.c`里的，这里只是指定了预期文件的名称。

如果`xmake`的测试配置里能直接提供文件对比功能，那就更方便了，我们只需要写下如此的配置即可：

```lua
add_tests("expect_file", {rundir = os.projectdir().."/test/hello", runargs = {"hello.z"}，expected_output_file = "hello_expect.asm"})
```

## 转译器的测试

转译器的测试也是基于文件的，因此和编译器测试很像，甚至我把他们都放在同一个运行目录里了。

不同之处在于：

- 转译不需要考虑跨平台
- 转译的输出文件分别是固定的`app.c`、`app.py`和`app.js`文件
- 预期的输出文件也可以写成固定的`*_expect.c`、`*_expect.py`和`*_expect.js`文件，其中*是测试用例名称，例如`hello_expect.c`。

转译器的测试代码`test_tranpiler.c`如下：

```c
#include <stdio.h>
#include <string.h>
#include "util.h"
#include "transpiler.h"

int main(int argc, char** argv) {
    if (argc < 4) {
        printf("Error: args: c|py|js <hello.z> <hello_expect.c>\n");
        return -1;
    }
    char *cmd = argv[1];
    if (strcmp(cmd, "c") == 0) {
        trans_c(argv[2]);
        return compare_file("app.c", argv[3]);
    } else if (strcmp(cmd, "py") == 0) {
        trans_py(argv[2]);
        return compare_file("app.py", argv[3]);
    } else {
        trans_js(argv[2]);
        return compare_file("app.js", argv[3]);
    }
}
```

由于转译到C、Python和JS的流程完全相同，我们可以一次性测试是三个情况。

这个测试函数接收三个参数：

- 转译目标，可以是`c`、`py`或`js`
- 要转译的源码文件
- 用来对比的预期输出文件

在`xmake.lua`配置文件里，写法和编译器的差不多：

```lua
target("test_transpiler")
    set_kind("binary")
    set_default(false)
    add_includedirs("src")
    add_files("src/*.c")
    remove_files("src/main.c")
    add_files("test/test_transpiler.c")
    add_tests("hello_c", {rundir = os.projectdir().."/test/hello", runargs = {"c", "hello.z", "hello_expect.c"}})
    add_tests("hello_py", {rundir = os.projectdir().."/test/hello", runargs = {"py", "hello.z", "hello_expect.py"}})
    add_tests("hello_js", {rundir = os.projectdir().."/test/hello", runargs = {"js", "hello.z", "hello_expect.js"}})
```

区别一个是不需要判断操作系统了；另一个是这里把三种转义输出都一起测试了。

## 运行测试

现在，我们可以尝试运行测试了。

非常简单，直接`xmake test`即可：

```bash
$ xmake test
checking for Microsoft Visual Studio (x64) version ... 2022
checking for flags (-O2 -fp:fast) ... ok
> cl.exe "-O2" "-fp:fast" "-nologo"
checking for flags (-DNDEBUG) ... ok
> cl.exe "-DNDEBUG" "-nologo"
running tests ...
[ 16%]: test_compiler/hello      .................................... passed 0.015s
[ 33%]: test_interp/hello        .................................... passed 0.000s
[ 50%]: test_interp/hello1       .................................... passed 0.016s
[ 66%]: test_transpiler/hello_c  .................................... passed 0.000s
[ 83%]: test_transpiler/hello_js .................................... passed 0.016s
[100%]: test_transpiler/hello_py .................................... passed 0.000s

100% tests passed, 0 tests failed out of 6, spent 0.047s
```

可以看到，6个测试用例全部通过了。这里的输出还是很清晰的。未来项目更复杂之后，这样清晰的自动测试对我的帮助应该会很大。

如果测试出错，例如我们故意把解释器改错：

```c
// 执行AST
void execute(CallExpr *call) {
    log_trace("Executing %s(%s)...\n", call->fn, call->arg);
    // 打印call.arg
    printf("WRONG|%s\n", call->arg);
}
```

这里我们在执行代码时，不再打印`call->arg`的值，而是加上几个错误字符`WRONG|`。

这时再运行`xmake test`：

```bash
$ xmake test
checking for Microsoft Visual Studio (x64) version ... 2022
[ 15%]: compiling.release src\interp.c
[ 39%]: compiling.release src\interp.c
[ 63%]: compiling.release src\interp.c
[ 81%]: linking.release test_transpiler.exe
[ 84%]: linking.release test_compiler.exe
[ 87%]: linking.release test_interp.exe
running tests ...
[ 16%]: test_compiler/hello      .................................... passed 0.062s
[ 33%]: test_interp/hello        .................................... failed 0.047s
[ 50%]: test_interp/hello1       .................................... failed 0.016s
[ 66%]: test_transpiler/hello_c  .................................... passed 0.016s
[ 83%]: test_transpiler/hello_js .................................... passed 0.015s
[100%]: test_transpiler/hello_py .................................... passed 0.000s

66% tests passed, 2 tests failed out of 6, spent 0.156s
```

可以看到，`test_interp/hello`和`test_interp/hello1`两个用例`fail`了。

但是具体是怎么错的呢？想要查看错误内容，只要加上`-D`选项即可（`-D`应该是Detail的意思）：

```bash
$ xmake test -D
running tests ...
[ 16%]: test_compiler/hello      .................................... passed 0.016s
[ 33%]: test_interp/hello        .................................... failed 0.016s
not matched passed output: Hello, world!, actual output: WRONG|Hello, world!
[ 50%]: test_interp/hello1       .................................... failed 0.000s
not matched passed output: Now!, actual output: WRONG|Now!
[ 66%]: test_transpiler/hello_c  .................................... passed 0.015s
[ 83%]: test_transpiler/hello_js .................................... passed 0.000s
[100%]: test_transpiler/hello_py .................................... passed 0.000s

66% tests passed, 2 tests failed out of 6, spent 0.047s
```

可以看到，实际的输出`actual output`是"WRONG|Hello, world!"，与预期的"Hello, world!"不一致，这才导致了测试失败。

至此如何进行单元测试的问题就解决了！

还有一点值得注意，和`xmake run`不一样，`xmake test`会自动调用`xmake build`，编译所有的源码文件，所以我们每次修改了代码之后直接运行`xmake test`即可。

一旦写好了测试用例，这样的开发流程会比之前的手动测试要方便很多。每次改一部分代码，直接`xmake test`就都解决了。


## 小结

现在只剩REPL没有写测试了。但考虑到REPL实际上就是交互式的解释器，暂时不需要独立的单元测试。
以后如果有需要，我再考虑怎么去给这种互动流程写自动测试。

至此，我们可以再提交一个版本了。

```bash
$ git commit -a -m "步骤9：添加自动测试"
$ git tag -a v0.0.9 -m "步骤9：添加自动测试"
$ git push
```

万事俱备，只欠东风。我们已经把Z语言的整个框架都搭好了，接下来开始真正的编译器开发之旅吧！

第二大章，我会实现一个计算器，可以进行整数的加减乘除运算，并可以用括号来指定优先级。

实现计算器的过程会涉及到编译器的几个关键技术：

- 词法分析
- 语法分析
- 表达式解析
- 优先度解析（递归下降解析，或者Pratt解析）

第三大章，我会实现编程语言最基础的几个拼图：

- 自定义函数
- 条件语句（`if-else`）
- 循环语句（`for`）
- 分支语句（`when`）

敬请期待！

