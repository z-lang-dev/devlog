# 哈希表

为了支持存量的查找，编译器里需要实现一个哈希表，用来存储所有的存量名称与数值的一一对应。

可惜的是，C语言并没有标准的哈希表实现，所以我只有两个解决办法：

- 寻找一个第三方实现
- 参照网上的教程，自己实现一个

我的第一选择当然是找一个第三方实现，于是搜索了一圈，找到了以下几个实现：

哈希库 | 优点 | 缺点 | 其他
--- | --- | --- | ---
[glib](https://docs.gtk.org/glib/struct.HashTable.html) | 稳定且久经考验 | 需要引入整个glib库，依赖太多，太重量级了 | GTK的官方实现 
[apr](https://apr.apache.org/docs/apr/1.4/group__apr__hash.html) | Apache官方库 | 依赖太多 | Apache Portable Runtime的一部分
[uthash](https://troydhanson.github.io/uthash/) | 单个头文件，支持任意struct作key，用户多 | 全是宏，看不懂 | 3.7k stars
[klib](https://github.com/attractivechaos/klib) | 单个头文件，用户多 | 全是宏，看不懂 | 3.9k stars
[hashmap](https://github.com/tidwall/hashmap.c) | .h+.c，用户较多 | 实现较复杂 | 619 stars
[ht](https://github.com/benhoyt/ht) | 有配套[博客文章](https://benhoyt.com/writings/hash-table-in-c/)，实现简单 | 没人用 | 107 stars
[coucal](https://github.com/xroche/coucal) | cuckoo-hashing，基于论文的实现 | 没人用 | 32 stars
[hashtable](https://github.com/goldsborough/hashtable) | .h+.c，实现简单 | 没人用、没有文档 | 40 stars

总结一下，上面的第三方库大概分为三种：

- glib或apr这样的官方库，优点是应该很好用，缺点是依赖太多，不适合在我这种小项目中使用。
- uthash/klib 优点是用的人挺多，应该比较好用，并且宣称性能优良。这俩应该是独立开源实现里的精品。缺点是为了做到通用性，实现里全是宏，暂时看不懂也改不动，不知道是否适合Z项目。
- 后面几个个人开发的项目，优点是实现相对简单，缺点是没有经过验证。

另外，读过《Crafting Interpreters》（简称CI）的HashTable一章，感觉他讲得非常好，所以我也想自己实现一个。
上面的项目里也有一个`ht`有配套的实现博客文章，讲得挺详细。

所以我最终决定分3步走：

1. 先参考CI书里的讲解和ht的文章，自己实现一个最简单的版本。
1. 根据Z的进一步开发，收集实际需求，再考虑是否需要引入第三方库。
1. 研究uthash和klib的实现，看看能不能修改它们来适应Z的需求。

考虑到哈希表在编译器中的重要作用，我决定还是要自己掌握好它。

更何况这样做的话，才符合Z语言“从零开始”的特色，以及“学习与探索”的初衷嘛。

## 基本原理

基本原理我觉得就不用赘述了，《CI》这本书里讲得特别清楚，图文并茂的，我没什么话说。

这里是《CI》书讲`Hash Table`的的章节：[Hash Tables](https://craftinginterpreters.com/hash-tables.html)。大家自己去看吧。

要说英语看不懂怎么办？浏览器的翻译按钮足够用了哦。

另外，`ht`的文章也值得一看：[How to implement a hash table (in C)
](https://benhoyt.com/writings/hash-table-in-c/)。

非要我一句话总结的话，大概会这么说：所谓哈希表，就是利用哈希函数的特性，快速把复杂的字符串定位到哈希表中的某一个位置上，还不容易重复。

看完这两篇文章，如果理解了什么是哈希函数，什么是桶（bucket），什么是冲突（collision），解决冲突的两种算法模式：独立链表（separate chaining）和开放地址（open addressing），那就可以着手自己实现了。这几个概念的名字都不太好，但是《CI》书里画出了非常直观的图，一看就懂。

## 实现步骤

那我应该怎么做呢？

直接抄《CI》的吗？似乎不好，不说版权问题，面子也过不去啊。

那么把《CI》的实现和`ht`的实现结合起来呢？似乎是不错的办法。
缝一家会被骂，多缝几家就成了缝合怪了。

我看了`ht`的文章，他把哈希表和更简单的“顺序查找”和“二分查找”做了对比，
非常直观，这一点我也想借鉴一下。

所以我的计划是，先实现最简单的“顺序查找”，然后再实现哈希表。

二分查找我就不做了，还要自己做个字符串搜索，暂时没必要；而且它也没比最简单的哈希表容易多少。

## 需求

再次明确一下需求：

对于存量的读写来说，需求就是上一章提到的两个函数：

```c
// 存入存量的值
void set_val(char *name, int val);

// 获取存量的值
int get_val(char *name);
```

不管背后用的是数组也好、哈希表也好、红黑树也好，
总之有了新的名称，能够存进去；
遇到要用某个存量，能够按照名字查出来就行。

我们上一节限定了存量的名字只能是`a`，本节就要扩大到所有字符串了。

另外，未来还有个需求，就是对于`value`，现在只支持`int`型，
但未来需要支持所有的类型，包括自定义类型，所以还得想办法扩展它。

下面来做第一步：实现最简单的“顺序查找”。

## 顺序查找

如果完全不考虑性能，我们搞个动态数组，把所有的名称都存进去即可。

需要注意的是：

- 存进去的时候不要存重复了，得查找一遍是不是以前存过这个名字了。
- 取出来的时候也要查找一遍，最坏情况下要找遍整个数组，才能确定找不到。

因为又有名字又有值，只存一个名称肯定不够，我们设计一个结构体：

```c
typedef struct Entry Entry;

struct Entry {
    char *key;      /**< 用来索引的键 */
    int value;      /**< 需要存储的值 */
};
```

这里的`key`其实就是存量的名称。

我们先用一个动态数组来存放所有程序中用到的存量，每个存量对应一个`Entry`结构体。

```c
typedef struct ValueArray ValueArray;
struct ValueArray {
    int size; // 当前的尺寸
    int cap; // 总的容量
    Entry **entries; // 存量的数组
};
```

这个数组提供三个操作：

```c
// 新建一个数组
ValueArray *new_value_array();

// 判断是否已经存在了
bool array_has(ValueArray *arr, char *key);

// 存入一个存量，如果存在就更新它的值
void array_set(ValueArray *arr, char *key, int value);

// 获取一个存量，如果不存在就返回0
int array_get(ValueArray *arr, char *key);
```

由于是顺序查找，所以这几个操作都要遍历整个数组，直到找到为止。
它们的实现都很直观：

```c
ValueArray *new_value_array() {
    ValueArray *arr = calloc(1, sizeof(ValueArray));
    arr->cap = DEFAULT_ARRAY_CAP; // 默认值是16
    arr->size = 0;
    arr->entries = calloc(arr->cap, sizeof(Entry));
    return arr;
}

bool array_has(ValueArray *arr, char *key) {
    // 遍历并比较
    for (int i = 0; i < arr->size; i++) {
        Entry *ent = arr->entries[i];
        if (strcmp(ent->key, key) == 0) {
            return true;
        }
    }
    return false;
}

void array_set(ValueArray *arr, char *key, int value) {
    for (int i = 0; i < arr->size; i++) {
        Entry *ent = arr->entries[i];
        if (strcmp(ent->key, key) == 0) {
            ent->value = value;
            return;
        }
    }
    // 全部遍历了还没找到，就新建一个
    Entry *ent = calloc(1, sizeof(Entry));
    ent->key = key;
    ent->value = value;
    arr->entries[arr->size++] = ent;
}

int array_get(ValueArray *arr, char *key) {
    for (int i = 0; i < arr->size; i++) {
        Entry *ent = arr->entries[i];
        if (strcmp(ent->key, key) == 0) {
            return ent->value;
        }
    }
    // 全部遍历了还没找到，直接返回0
    return 0;
}
```

可以看到，顺序查找的方式就是`for`循环配合`strcmp`比较。
由于每个操作都需要遍历一遍，且每个字符串都要`strcmp`，即遍历了整个字符串，
因此这个操作还是很繁琐的。

不过在变量较少的情况下，其实性能也还好。
按照`ht`的文章里的测试，只有六七个以内的存量时，并不比哈希表慢。

注意，这个实现里，并没有考虑数组被填满的情况。

实际上，在`array_set`里，如果数组已经被填满了，就应该扩容，
在写入`entries`之前，判断一下`size`和`cap`的关系：

```c
// 没找到，就新建一项
Entry *ent = calloc(1, sizeof(Entry));
ent->key = key;
ent->value = value;

// 如果已经满了，就扩容
if (arr->size + 1 >= arr->cap) {
    arr->cap *= 2;
    arr->entries = realloc(arr->entries, arr->cap * sizeof(Entry));
}

// 写入数组
arr->entries[arr->size++] = ent; 
```

这样，最简单的“顺序查找”就实现了。

我们修改解释器的`get_val()`和`set_val()`函数，改为调用这个数组的接口：

```c
static ValueArray *values;

static void set_val(char *name, int val) {
    array_set(values, name, val);
}

static int get_val(char *name) {
    return array_get(values, name);
}
```

搞一个全局的数组`values`，并且在`interp`入口出初始化它：

```c
void interp(char *code) {
    values = new_value_array();
    log_trace("Interpreting %s...\n", code);
    // ...
}
```

现在可以测试复杂一些的句子了：

```c
$ xmake run z interp "let a=15;let b=4;a+b*5"
{kind:ND_PROG, exprs: [{kind:ND_LET, name: a, value: {kind: ND_INT, as.num: 15} }, {kind:ND_LET, name: b, value: {kind: ND_INT, as.num: 2} }, {kind:ND_LET, name: b, value: {kind: ND_INT, as.num: 4} }, {kind: ND_BINOP, op: +, left: {kind: ND_NAME, as.str: a}, right: {kind: ND_BINOP, op: *, left: {kind: ND_NAME, as.str: b}, right: {kind: ND_INT, as.num: 5} } }]}
----- END ----
Executing ...
------------------
35
```

成功了！当然，这里没有测试超过16个存量的情况，但是暂时也不需要，所以等以后实现了数组再来测试。

现在有了可以用的`get_val()`和`set_val()`，我们的定量特性在解释器里已经能够运行了。

但是既然已经说了要实现一个初步的哈希表，这个事情还是趁热打铁做了吧。
然后再去处理编译器和转译器的对定量的支持。

注意：这里的定量暂时还都是全局变量，从全局的`values`里读写。
以后如果要实现局部存量，我们得先设计一个视野（`scope`）概念，再在每一级视野里都存放一个`values`，
这样就能支持局部存量了。

## 哈希表

哈希表最简单的实现其实和顺序查找差不多，只是查找方式不同而已。

我们先给哈希表建一个结构体，和顺序查找的基本一致：

```c
struct HashTable {
    int size;           /**< 当前的大小 */
    int cap;            /**< 容量 */
    Entry **entries;    /**< 实际的存储数组 */
};
```

为什么也用一个动态数组呢？这是因为我选择了更容易实现的开放地址法（open addressing）。
所谓开放地址法，就是说如果哈希查找发现冲突了，就直接继续往后找个空的地方占下来。

第一步，先不考虑冲突，直接实现一个最简单的哈希查找。
这一步除了查找的方式与顺序查找不同，其他都一样：

```c
// 新建一个哈希表
HashTable *new_hash_table() {
    HashTable *hash = calloc(1, sizeof(HashTable));
    hash->cap = DEFAULT_HASH_CAP;
    hash->size = 0;
    hash->entries = calloc(hash->cap, sizeof(Entry));
    return hash;
}

// 检查key是否存在
bool hash_has(HashTable *hash, char *key) {
    int idx = hash_idx(hash, key);
    return hash->entries[idx] != NULL;
}

// 根据key设置value，注意现在还没有处理冲突或扩容的事情
void hash_set(HashTable *hash, char *key, int value) {
    int idx = hash_idx(hash, key);
    if (hash->entries[idx] == NULL) {
        hash->entries[idx] = calloc(1, sizeof(Entry));
    }
    Entry *ent = hash->entries[idx];
    ent->key = key;
    ent->value = value;
}

// 根据key获取value
int hash_get(HashTable *hash, char *key) {
    int idx = hash_idx(hash, key);
    Entry *ent = hash->entries[idx];
    return ent->value;
}
```

这是一个最简单的实现，也是一个错误的实现。
因为`hash_set`里既没有冲突，就可能会覆盖掉其他key的值。
而没有处理冲突，就没法判断是否已满，也就没法扩容了。

我们下一步再解决这俩问题。
先看看哈希查找的实现。

三个接口操作`hash_has`、`hash_set`、`hash_get`都调用了`hash_idx`来查找存量。
这个`hash_idx`就是哈希查找与顺序查找的最大区别所在。

它的实现如下：

```c
// 计算一个字符串的哈希值。
static int hash_code(char *key) {
    int h = 0;
    while (*key != '\0') {
        h = h * 31 + *key;
        key++;
    }
    return h;
}

// 根据哈希值算出索引
static int hash_idx(HashTable *hash, char *key) {
    int h = hash_code(key);
    return h % hash->cap;
}
```

原理很简单：既然用`strcmp`逐字符对比字符串太慢了，那就用一个`hash_code`函数把字符串转换成整数，
然后直接那这个整数做索引去数组里取结果就行了。
如果整数超过了数组的范围怎么办，简单，直接取模求个余数就行了。

这里的`hash_code`用的是最最简单的方式，就是把每个字符的ASCII码加起来，当然，为了避免太容易重复，还是先乘了个质数31。

这个实现比《CI》书中的实现还基础，它用的是`FNV-1a`算法，虽然简单，但是至少能够实用了：

```c
static int hash_code(char *key) {
    uint32_t hash = 2166136261u;
    while (*key != '\0') {
        hash ^= *key++;
        hash *= 16777619;
    }
    return hash;
}
```

路数和我写的差不多，但是这俩魔法数`2166136261u`和`16777619`是怎么来的呢？
我就不知道了。
反正实际证明`FNV-1a`的冲突率表现比`31`要好多了。

只要字符串对应的整数不容易重复，那么就不太容易出现冲突。

冲突的可能来源于两个方面：

1. 两个不同的字符串，通过`hash_code`计算出来的数直接就相等了。
1. `hash_code`不相同，但是取模后的余数相同了。

前者依靠更巧妙的哈希算法来改善，后者就只能靠扩容来解决了。

两个办法都想了以后，仍然还冲突的话，怎么办呢？
这就要想办法解决冲突了。两种办法：

- 冲突了不要紧，同一个索引，可以多存几个值就行了。那怎么实现呢？在索引的位置串一个链表就行了。
这个办法叫做“独立链表法”（separate chaining）。按照我的说法就是“叠叠乐”。
- 索引位置被占了，那就继续占下一家。那么下一家的人来了发现被占了怎么办？继续占领下一家呗。直到数组到头了，那就回到开头继续走，直到整个数组都快满了，再考虑扩容。这个办法叫做“开放地址法”（open addressing）。按照我的说法就是“占坑法”。

《CI》选择的是“占坑法”，我也觉得这个更容易实现，所以也走这条道路了。

首先判断坑是不是被“别人”占了，判断的办法是：

```c
int idx = hash_idx(hash, key);
bool is_occupied = (hash->entries[idx] != NULL) && (strcmp(hash->entries[idx]->key, key) != 0);
```

即`idx`所在的位置有人在用，但它的`key`又和我们的不同。

于是`hash_set`要处理三种情况：

- 位置是空的，直接新建一项并占领
- 位置是被自己占的，那就直接更新
- 位置是被别人占的，那就继续往后找，直到找到空的位置，再新建占领

为了方便处理，我把这三个逻辑的判断顺序改一下：

- 位置是被自己占的，那就直接更新（即最优情况）
- 位置是被别人占的，那就继续往后找，直到找到空的位置
- 现在位置一定是空的了，新建一项并占领

写成代码就是这样：

```c
void hash_set(HashTable *hash, char *key, int value) {
    int idx = hash_idx(hash, key);
    if (hash->entries[idx] != NULL) {
        Entry *ent = hash->entries[idx];
        char *exist_key = ent->key;
        if (strcmp(exist_key, key) == 0) { 
            // 如果key相同，说明位置是自己占的，直接更新
            ent->value = value;
            return;
        } else {
            // 冲突了，寻找下一个空位
            idx = (idx + 1) % hash->cap;
            while (hash->entries[idx] != NULL) {
                idx = (idx + 1) % hash->cap;
            }
            // 注意，这里没有处理找了一圈儿没找到的情况，因为扩容的问题另外处理
            // 所以假设循环结束时，总会找到一个空位
        }
    }
    // 找到了空位，新建一项并写入
    hash->entries[idx] = calloc(1, sizeof(Entry));
    Entry *ent = hash->entries[idx];
    ent->key = key;
    ent->value = value;
}
```

用这个`HashTable`替换之前的`ValueArray`，并修改`get_val`和`set_val`，改为调用`hash_set`和`hash_get`，就可以测试了。

```bash
$ xmake r z interp "let a=15;let b=2;let b=4;a+b*5"
...
----- NODE ----
{kind:ND_PROG, exprs: [{kind:ND_LET, name: a, value: {kind: ND_INT, as.num: 15} }, {kind:ND_LET, name: b, value: {kind: ND_INT, as.num: 2} }, {kind:ND_LET, name: b, value: {kind: ND_INT, as.num: 4} }, {kind: ND_BINOP, op: +, left: {kind: ND_NAME, as.str: a}, right: {kind: ND_BINOP, op: *, left: {kind: ND_NAME, as.str: b}, right: {kind: ND_INT, as.num: 5} } }]}
----- END ----
Executing ...
------------------
35
```

也成功了！这次修改一次通过，看来我的C功力还是有提高的。

但是跑这么简单的例子也测不出来占用啊什么的边界情况，所以先不管了吧。
等到时候真能做出更复杂的用例来时，再来调试这段实现。

注意：现在的哈希实现其实还是没有考虑扩容的问题，所以这个实现其实是会遇到占满以后就再也找不到空位的情况。

为了解决它，我加个最简单的扩容逻辑：每次调用`hash_set`时，先判断一下`size`和`cap`的比例，如果大于某个数，就表示哈希表已经比较拥挤了，就扩容一倍。

那么为什么不直接等到满了再扩容呢？这是哈希表和顺序查找的一个重要区别。
哈希的特色就是空间越大，越不容易冲突。
从上面函数的“占坑”逻辑也可以看出，如果冲突了，再去找坑位是比较麻烦的事情。
当更多人占了其他人的坑位时，找坑位就更难了。
也就是说，找坑位的难度和哈希表的拥挤程度是成正比的。

极端情况下，每个新来的人都需要跑遍整个哈希表才能找到坑位，这就退化成比顺序查找还慢了，毕竟多了一步哈希计算。

所以最好的办法，就是能在不那么拥挤的情况下，就预先扩容。
而`size`/`cap`的比例，就是一个很好的衡量标准。
我们称之为`load factor`，即负载因子。这个术语很晦涩，但它的意思其实就是“坑快满了”。
一般用`0.75`作为阈值，即当`size`/`cap`大于`0.75`时，就扩容。

我们可以在`hash_set`的开头加上判断扩容的逻辑：

```c
void hash_set(HashTable *hash, char *key, int value) {
    // 如果size/cap超过LOAD_FACTOR，就扩容一倍
    if ((double) hash->size / (double) hash->cap > LOAD_FACTOR) {
        hash->cap *= 2;
        hash->entries = realloc(hash->entries, hash->cap * sizeof(Entry));
    }
    // ...
}
```

至此，最简单的哈希表就做出来了！

对于现阶段的Z语言来说，这个已经完全够用了。虽然它可能比顺序查找还慢一点。

后面我会遇到新的需求，比如支持跟多的存值类型，比如用哈希表来支持Z语言的字符串，
甚至直接在Z语言里实现哈希表。到那个时候再进一步扩展这个哈希表实现吧。

这个段代码应该不影响之前测试的用例，不过我们还是把所有用例都跑一遍再提交代码。

```bash
$ xmake test
[ 13%]: compiling.debug src\hash.c
[ 15%]: compiling.debug src\interp.c
[ 35%]: compiling.debug src\hash.c
[ 37%]: compiling.debug src\interp.c
[ 56%]: compiling.debug src\hash.c
[ 58%]: compiling.debug src\interp.c
[ 84%]: linking.debug test_compiler.exe
[ 86%]: linking.debug test_interp.exe
[ 90%]: linking.debug test_transpiler.exe
running tests ...
[  1%]: test_compiler/add_sub         .................................... passed 0.063s
[  3%]: test_compiler/calc            .................................... passed 0.031s
[  5%]: test_compiler/hello           .................................... passed 0.016s
[  7%]: test_compiler/neg_group       .................................... passed 0.015s
[  9%]: test_compiler/read_file       .................................... passed 0.016s
[ 11%]: test_compiler/simple_add      .................................... passed 0.016s
[ 13%]: test_compiler/simple_int      .................................... passed 0.015s
[ 15%]: test_compiler/single_int      .................................... passed 0.000s
[ 17%]: test_compiler/two_exprs       .................................... passed 0.000s
[ 19%]: test_compiler/write_file      .................................... passed 0.016s
[ 21%]: test_interp/add_sub           .................................... passed 0.046s
[ 23%]: test_interp/calc              .................................... passed 0.000s
[ 25%]: test_interp/hello             .................................... passed 0.016s
[ 26%]: test_interp/hello1            .................................... passed 0.000s
[ 28%]: test_interp/let               .................................... passed 0.000s
[ 30%]: test_interp/neg_group         .................................... passed 0.016s
[ 32%]: test_interp/simple_add        .................................... passed 0.000s
[ 34%]: test_interp/simple_int        .................................... passed 0.000s
[ 36%]: test_interp/single_int        .................................... passed 0.000s
[ 38%]: test_stdz/hello               .................................... passed 0.016s
[ 40%]: test_transpiler/add_sub_c     .................................... passed 0.016s
[ 42%]: test_transpiler/add_sub_js    .................................... passed 0.015s
[ 44%]: test_transpiler/add_sub_py    .................................... passed 0.000s
[ 46%]: test_transpiler/alert_js      .................................... passed 0.016s
[ 48%]: test_transpiler/calc_c        .................................... passed 0.000s
[ 50%]: test_transpiler/calc_js       .................................... passed 0.015s
[ 51%]: test_transpiler/calc_py       .................................... passed 0.000s
[ 53%]: test_transpiler/hello_c       .................................... passed 0.016s
[ 55%]: test_transpiler/hello_js      .................................... passed 0.000s
[ 57%]: test_transpiler/hello_py      .................................... passed 0.016s
[ 59%]: test_transpiler/neg_group_c   .................................... passed 0.015s
[ 61%]: test_transpiler/neg_group_js  .................................... passed 0.000s
[ 63%]: test_transpiler/neg_group_py  .................................... passed 0.000s
[ 65%]: test_transpiler/read_file_c   .................................... passed 0.016s
[ 67%]: test_transpiler/read_file_py  .................................... passed 0.016s
[ 69%]: test_transpiler/simple_add_c  .................................... passed 0.000s
[ 71%]: test_transpiler/simple_add_js .................................... passed 0.015s
[ 73%]: test_transpiler/simple_add_py .................................... passed 0.016s
[ 75%]: test_transpiler/simple_int_c  .................................... passed 0.000s
[ 76%]: test_transpiler/simple_int_js .................................... passed 0.015s
[ 78%]: test_transpiler/simple_int_py .................................... passed 0.000s
[ 80%]: test_transpiler/single_int_c  .................................... passed 0.016s
[ 82%]: test_transpiler/single_int_js .................................... passed 0.000s
[ 84%]: test_transpiler/single_int_py .................................... passed 0.000s
[ 86%]: test_transpiler/two_exprs_c   .................................... passed 0.000s
[ 88%]: test_transpiler/two_exprs_js  .................................... passed 0.000s
[ 90%]: test_transpiler/two_exprs_py  .................................... passed 0.015s
[ 92%]: test_transpiler/use_c         .................................... passed 0.000s
[ 94%]: test_transpiler/use_js        .................................... passed 0.016s
[ 96%]: test_transpiler/use_py        .................................... passed 0.016s
[ 98%]: test_transpiler/write_file_c  .................................... passed 0.000s
[100%]: test_transpiler/write_file_py .................................... passed 0.015s

100% tests passed, 0 tests failed out of 52, spent 0.594s
```

本节的修改没有影响其他测试用例，通过了！

现在可以提交代码了：

```bash
$ git commit -a -m "步骤25：哈希表"
$ git tag -a v0.0.25 -m "步骤25：哈希表"
$ git push
```

## 小结

我在写本节的代码之前还以为哈希表是一件非常麻烦的事情，
但自己真写下来，发现还是挺轻松惬意的。

可能是因为有《CI》一书的参考吧，也可能是因为这回真弄懂了哈希表相关的概念，
并且是地按照由浅到深的顺序来拆分实现。

这给我未来实现Z的各种复合类型，比如数组、字典等，提供了更多的信心。

现在有了哈希表，我们的定量支持就算是初步完成了。虽然它还只是个全局存量，也没有真正去判断是否修改。
这些放在后面有需求的时候来实现吧。

比如局部存量和全局存量，至少要实现了常量、语句块、自定义函数，有了视野（即作用域）的需求之后，再一起实现。

而是否修改的判断，则放在实现变量`mut`的时候同时进行。因为`let`和`mut`的唯一区别就是需要编译器判断是否被修改。现阶段，我们就把`let`当做`let`和`mut`的共同体来看就行了。

下一节，我们先完成编译器和转译器对定量的基本支持。
