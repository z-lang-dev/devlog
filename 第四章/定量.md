# 定量

第一节我们实现了基本的定量，但是直到上一节做好了哈希表，才能在解释器里跑出来。

本节继续定量的工作，实现在编译器和转译器里对定量的初步支持。

## 编译器

编译器里，定量的存储和解释器完全不同。

在解释器里，我们把定量存放在一个哈希表里，这样可以方便地查找和修改。
但在编译器里，所有的东西最终都要变成汇编，所以定量也要存储到汇编里去。

在前两章我们已经知道，汇编里把常量存放在`.data`字段里，
而`.data`字段是全局的，又是只读的，
适合用来存放常量，会在整个程序运行期间一直存在。
这样的特性，让`.data`字段只适合存放常量和全局的定量。

局部的定量和变量，生命周期都比较短，汇编中一般把他们存放在运行栈中。

在上一章函数中，我们也提到过，如果参数超过4个（Linux下是6个），多出来的参数就是用栈来传递的。
换句话说，函数参数和局部的存量，本质上是非常相似的。

对于函数内部的代码来说，存在栈上的参数和存在栈上的局部存量，并没有什么区别。

也就是说，一旦实现了局部存量，那么要扩展函数，让它支持更多的参数，也不是很麻烦的事情。

我们先来了解一下运行栈是怎么存放数据的。

## 运行栈（The Stack）

我们经常听说一个变量存在“栈上”或者“堆上”，但是我一直没搞清楚它们到底在哪里。

只有一个大概的印象：栈是一个很近的地方，所以栈上的变量访问很快；而堆似乎是个很远的地方，只能通过指针跳转去访问，还要申请空间、释放空间，所以比较慢。

还常听到这样一种说法：“能放在栈上，就不要放在堆上”。

其实画个图，就能看得很清楚了：

![memory_layout](./memory_layout.png)

注意：这个图中，为了方便理解栈，内存的地址是从上往下增长的。也就是说，加入从零开始的话，那么最上面是0x00000000，最下面是0xFFFFFFFF。

整个图是一段运行的程序（即一个进程）的内存布局，从上到下依次是：

- .text/.code段：即程序的代码本身。这段内存是只读的。
- .data数据段：存放全局变量和常量。这段内存分成两个部分，一部分是只读的，用来存放全局变量。
- .bss段：存放未初始化的全局变量。这段内存是可读写的。
- heap：堆。这就是我们常说的堆。它的大小是不固定的，可以向下动态增长。
- stack：栈。这就是我们常说的栈。它的大小也不是固定，它从程序的最后一段内存开始，向上动态增长。
- 命令行参数区：这里存放了命令行的参数。

值得注意的是，程序分配了一大块内存，而堆和栈之间的内存是空闲的。堆和栈放在两头，向中间增长，这样可以确保它们都有足够的空间。

但也有一种极端的情况，就是栈或者堆一直增长，直到两者撞到了一起，这时候就内存爆炸了。

我们常说的“stack overflow”就是这个意思，它往往是由于递归调用函数，但是没有写好停止条件，就好不停地调用新的函数，增加栈空间。

这个图中，如果忽略掉最下面的命令行参数区的话，基本可以把栈看做是在整个程序的最底端开始，向上增长的一段。

那么如何理解栈的生长（以及销毁）呢？

我们知道，每个函数的调用，都需要在栈上存储一些内容，它们占据一小块内存。这个函数运行结束之后，就会清空这段内存。

如果把每个函数看做一个盘子的话，那么栈就是一叠从下往上垒的盘子。
每调用一个函数，就往上再叠一个盘子，栈就增长了；
函数结束返回时，盘子就被拿走了，栈就缩短了。
如果函数内部又调用了其他的函数，那就再往上叠盘子。

举个例子，比如这个程序：

```c
#include <stdio.h>

int add(int a, int b) {
    return a + b;
}

int main() {
    int c = add(1, 2); // 第一个函数调用
    printf("%d\n", c); // 第二个函数调用
    return 0;
}
```

最底下的一个盘子就是整个进程的入口，但它往往并不是我们写的`main`函数，而是系统自己启动的一个函数。
例如在Linux中，启动的函数叫`_start`，它是最底下的盘子。
它会调用`main`函数，所以`main`是第二个盘子。

`main`函数开始时，整个栈里只有两个盘子。
当`main`调用第一个函数，即`add`的时候，就叠了三个盘子了。

假如我们用调试器打断点，停在`add`函数里的`return a+b`这一行，就会发现，此时栈里有三个盘子，从下到上分别是`_start`、`main`、`add`。这也是栈最高的时候。

`add`返回之后，它的盘子会被拿走，栈里又只有两个盘子了。再调用`printf`，又叠了一个盘子。

整个程序的运行过程中，栈里最多叠了三层：`_start`、`main`、`add`，或者`_start`、`main`、`printf`。

那么参数和局部变量在哪里呢？就在这些盘子里。

放大看看，每一个函数占用的空间实际上可以看做一个方块。
里面一条条的，就是这个函数运行时用到的数据。

这个方块，也可以叫做方框（frame），就是我们常说的“栈帧”（stack frame）。“帧”其实就是“框”的意思。

那么栈帧里的数据又是怎么排布的呢？都有哪些数据？函数在调用前后它是怎么变化的呢？
局部变量又是怎么存放和使用的呢？

我们来细细观察放大的图，看看栈帧的内部。

## 栈帧

因为每个栈帧都对应一个函数，所以为了方便与调用栈区分，之后我们都叫它“函数帧”。

函数帧的内部结构如下图：

![stack_frame](./stack_frame.png)

图中有几个关键的部分需要说明：

- 栈指针（`rsp`）：指向栈顶的指针。
- 返回地址（`return address`）：调用函数的下一条指令的地址。
- 临时值（`temporary values`）：函数内部临时使用的值。
- 参数（`arguments`）：调用函数时传入的参数。
- 局部变量（`local variables`）：函数内部定义的变量。
- 上一个RBP（`previous RBP`）：调用函数的RBP的值。
- 基址指针（`rbp`）：指向栈帧的开头的指针。

注意：实际上并没有标准规定一个函数帧内的数据应该如何布局。只要能完成函数数据的存取功能，怎么布局都可以。甚至有的编译器为了对齐方便，会对函数帧的布局进行调换优化。
上图展示的是Linux下一个典型的函数帧的布局，但是在其他平台上可能会有所不同。

下面分别说明一下。

### 基址指针`rbp`

整个帧的最底端，叫做“基址指针”（`rbp`），因为它是帧内所有地址的基准。
注意：图中它是帧的底端，但由于函数栈实际上是从程序的末尾往回增长的，它的地址实际上是最高的。

`rbp`有两个作用：

- 作为一个函数帧内的基准地址，可以定位其他成员的位置。也就是说，所有的其他数据的地址都只需要用一个相对于`rbp`位置的偏移值`offset`来记录即可。需要用时候，用`[rbp-offset]`就能找到。
- 每个`rbp`所指向的位置，存储的是`上一个RBP`的位置。

如果我们顺着那个`rbp`找上去，到上一个`rbp`的位置，
就会发现它指向的是更上一个`rbp`的位置，如此类推，一直到整个帧的底端。

这是干什么用的呢？这些`rbp`形成了一个链表，可以轻松地从当前帧找到上一帧的位置，一直回溯到整个程序的入口。我们常用的`stack trace`就是靠它来实现的。

当程序出错时，操作系统可以根据这个链表找到出错函数的完整调用轨迹，方便定位错误所在。
在开发过程中，调试器也能利用它，帮助程序员轻松地在运行栈里游走。

我们在生成`main`函数时，其实就已经见过它了：

```asm
; prolog
push rbp
mov rbp, rsp

;...
8
; epilog
mov rsp, rbp
```

TODO: 图示`prolog`和`epilog`运行前后的栈帧变化。

每个函数开头都要运行的`prologue`，实际上做的就是记录`上一个rbp`的事情：

- `push rbp`，此时新的函数才刚开始，`rbp`还是上一个函数帧的基址，把他`push`到栈顶，就算是记录了“上一个`rbp`”了。此时栈顶`rsp`恰好也指向了这个地方。
- `mov rbp, rsp`，把`rbp`指针从之前的值切换成现在的栈顶位置，也就是“上一个`rbp`”的位置。这也就是未来整个新函数帧的地基。

接着运行正常程序，包括传递参数，存储局部变量之类的操作时，`rsp`就会继续增长了，但`rbp`会一直保持在函数帧的底端的位置。

最后，在函数结束时，`epilogue`运行`mov rsp, rbp`，就把整个栈直接缩减到了当前帧的底端，其实就相当于把当前帧清空了。这也就是我们上前面所说的“把盘子拿走”的操作。

### 栈指针`rsp`

整个帧的顶端，也就是函数栈的顶端，叫做“栈顶”，寄存器`rsp`（`stack pointer`）总是指向它。
我们所说的栈“增长”或着“缩减”，就是靠对这个寄存器进行加减法来实现的。

注意，这个栈顶虽然是栈的顶部，但是它指向的地址是整个帧的最低地址，这是因为整个栈是从程序内存的末尾（即最高地址）向程序开头部分反向增长的。

所以，如果我们要给栈增加8个字节的空间，用的是`sub rsp, 8`，而不是`add rsp, 8`。

所有的`push`和`pop`操作其实都是对`rsp`进行加减法。
上一小节所说的`prologue`和`epilogue`，其实都通过操作`rsp`来建立新帧，或者清空当前帧。

本节要实现的局部变量，也要通过操作`rsp`来分配空间。

### 参数和局部变量

比如，函数开始后，运行完`prologue`时，`rbp`和`rsp`都在当前帧的底端位置（这个为止存储的是“上一个rbp”的值）。

这时候，我们要做的第一步就是参数分配空间，第二步就是为局部变量分配空间。

假设这个函数：

```c
int add(int a, int b) {
    int c = a + b;
    return c;
}
```

它有两个参数，`a`和`b`，一个局部变量`c`。他们都是`int`型，即32位，占用4个字节。

那么编译器计算出来，参数需要的空间是4+4=8个字节，局部变量则是4个字节。

所以第一步工作，分配8个字节给参数空间，这么做：

```asm
sub rsp, 8
```

注意，上面说过栈空间增长的方向，越往上地址越低。所以用`sub`其实是增长的意思。

再分配4个字节给局部变量空间：

```asm
sub rsp, 4
```

这时候，`rsp`指向的位置，就是`c`的位置了。

如图所示：TODO：画图。

现在要读取或写入`a`、`b`、`c`的值，可以用`[rbp-offset]`的形式来访问：

- `a`：`[rbp-4]`
- `b`：`[rbp-8]`
- `c`: `[rbp-12]`

后面我们讨论局部存量时，就用这个策略来给局部存量分配空间、访问读写。

注意：这里为简单起见，没有考虑对齐的问题。实际操作时，操作系统会要求栈内的空间按照16个字节进行对齐，否则可能会出段错误。这个问题我会在具体实现局部存量内存分配时详细讨论。

### 临时空间

现在函数帧里有三种数据了：“上一个rbp”、“参数”、“局部变量”。

这三段数据的尺寸对每个函数来说都是固定的。

接下来的空间，就交给函数运行时临时使用了。
使用的办法是调用`push`或`pop`把某些临时数据压栈或出栈，
甚至可以直接对`rsp`进行加减操作来分配空间。
这些都是编译器的自由发挥的地方。

例如，我们在四则运算中，就遇到过这样的情况：

```c
4/2+2*3
```

我们在算出`4/2`的结果之后，它是存在`rax`里的，但是后面还要优先计算`2*3`，也需要用到`rax`，
为了不丢掉`4/2`的结果，我们就把`rax`压栈，等到`2*3`计算完毕之后，再把它`pop`出来。

所有遇到更高优先级的复杂操作，都需要把当前的临时结果压栈，等到需要使用的时候再`pop`出来。

这些计算的过程中，`rsp`就会根据临时数据的需要，不停地增长或缩减。

### 返回地址

函数运行中，遇到需要调用另一个函数的时候，就会执行`call`指令。
在`call`跳转到新的函数的指令地址之前，需要把返回的指令地址保存起来，
这样在调用函数返回的时候，就能立马知道该从哪条指令继续了。

这个地址就是“返回地址”（return address）。
它也往往是一个函数帧的最后一个成员。再往上的位置，就是新的函数帧了。

注意，它指向的不是栈上的地址，而是调用它的函数的指令地址。
具体的说，是调用它的函数的下一条指令的地址。

回顾一下上面的内存布局图，指令地址是存放在图中最顶上的`.text`或者`.code`区域的，在程序内存的开头，
和底部的栈所在的地方八竿子都打不着。

那么这个`返回地址`是怎么来的呢？没错，是`call`指令干的。`call`指令做的事情，就是先把当前`rip`的下一个地址（也就是如果调用完函数，下一个要执行的指令地址）`push`到栈上，然后再把`rip`改成目标函数的指令地址，开始执行的。

当调用的函数返回的时候，`ret`指令执行，会把这个地址`pop`出来，并传给`rip`指令寄存器，这样CPU下一步就能找到正确的地方执行了。

也就是说，`call`相当于执行了：

```asm
push rip
mov rip, [function_address]
```

而`ret`相当于：

```asm
pop rip
```

而`rip`寄存器，也就是`instruction pointer`，存放的是计算机下一个执行的指令地址。所有的跳转指令都是通过操作这个寄存器来实现的。

## 局部存量

现在弄清楚了调用栈（`call stack`）和函数帧（`stack frame`）的关系，我们就可以开始实现局部存量了。

上一节已经说过，存储局部存量的办法，就是在函数刚开始的时候分配一段空间，然后用`[rbp-offset]`的形式来访问。

这对我们的编译器有两个要求：

- 在编译的时候，就弄清楚函数里到底有几个局部存量，以及每个存量需要多少空间。
- 记录每个存量的偏移值`offset`，并和它的名字绑定。这样当我们需要使用存量的时候，用偏移值就能找到它。

由于现在只需要支持定量`let`，所以我们只需要对`ND_LET`进行处理，就足够搞定上面两个要求了。

我的初步想法是用一个哈希表来存放这些信息，哈希表的键是存量的名字，值是关于这个存量的元信息（metadata），包括它的类型、偏移值等等。

现在还没有实现`视野`（即作用域），所以只需要弄一个全局的哈希表就行了。也就是说，现在所有的定量都是全局的（或者说是属于`main`函数的）。

这和解释器里的做法类似，但是不同之处在于解释器里的哈希表是用来记录**运行时**的存量的，存放的是实际的数值；而这个哈希表存放的**编译期**的与存量相关的**元信息**。

```c
struct Meta {
    int seq; // 顺序
    int offset; // 偏移量
};
```

以后根据需求，还会在`Meta`里添加新的信息，例如类型、可见性、是否可以修改等等。

这时候，我遇到了哈希表遗留的问题：如何把`Meta`存入哈希表？

## 支持`Meta`的哈希表

我们之前的哈希表只能存放`int`类型的值，而现在要替换成`Meta`类型，所有的接口也要改动。

可惜C语言没有泛型，我试了一下类似`uthash`和`klib`之类的宏方案，没能够成功。
一个感觉，宏太难用了。

所以我打算回归最原始的办法：重复代码。

我把之前的哈希表的`Entry`修改为三种：

```c
// 这个是基类
struct Entry {
    char *key;      /**< 用来索引的键 */
};

// Int类型的Entry
struct IntEntry {
    Entry base;      /**< 基类 */
    int value;      /**< 存储的值 */
};

// 任意复合类型的Entry
struct ObjEntry {
    Entry base;      /**< 基类 */
    void *value;      /**< 存储的值 */
};
```

这里利用了C结构体的一个特性，即如果第一个成员是`Entry`的话，
那么`IntEntry*`和`ObjEntry*`类型的数据也可以当做`Entry*`来使用。

这样，我们就可以做一个统一的哈希表了。

结构体和之前仍然一样：

```c
struct HashTable {
    int size;           /**< 当前的大小 */
    int cap;            /**< 容量 */
    Entry **entries;/**< 实际的存储数组 */
};
```

但是实际存储的不再是`Entry*`，而是`IntEntry*`或者`ObjEntry*`。

由于`ObjEntry`的用途显然更广，我把默认的接口`hash_set`和`hash_get`换给它用了。
而`int`型的接口改用`hash_set_int`和`hash_get_int`。

```c
void hash_set_int(HashTable *hash, char *key, int value);
void hash_set(HashTable *hash, char *key, void *value);

int hash_get_int(HashTable *hash, char *key);
void *hash_get(HashTable *hash, char *key);
```

具体的实现和之前类似，只是要注意存入的实际数据是`IntEntry`或者`ObjEntry`了。

这种方法还是有3个麻烦的地方：

1. `IntEntry`和`ObjEntry`的`key`是`Entry`里的，所以要读取它，只能用`ent->base->key`。
1. 哈希表里的项取出来时仍然是`Entry*`类型，要获取`value`，必须进行类型转换`((IntEntry*)ent)->value`。
1. 最后，`hash_set_int`和`hash_set`的实现几乎一样，但是由于C没有类似泛型或模版的功能，
只能写两遍，以后要修改的时候就要修改两个地方，比较麻烦。

要在C语言里解决第3点，只能改用宏，因为宏是C唯一的代码生成机制。

但我觉得宏的可管理性太差了，且我创造Z语言就是为了能改进C的，
所以我打算不用宏。

宁可现在麻烦一点，也要坚持到Z做出类似泛型的代码生成功能来。
到时候，这部分重复的代码，就可以用Z来实现了。

这也是Z之所以要做转译C的原因之一：
为了将来能够尽快地、渐进地把编译器代码替代成Z本身，早日实现自举。

OK，现在有了支持`Meta`的哈希表了，我们只要多做一步`Meta`和`void*`的转换，
就可以把`Meta*`对象当做`ObjEntry->value`来对待了。

## 定量的元信息

新建`meta.h`和`meta.c`，把元信息相关的逻辑都放在这里。
`meta`和`parser`相互配合，实现定量的存储和访问。

我们在`meta.h`定义一下相关的接口：

```c
// 初始化元信息
void init_meta();

// 添加新的元信息
void set_meta(Meta *meta);

// 获得一个名称对应的元信息
Meta *get_met(char *name);
```

在`meta.c`里加上他们的实现，借助哈希表来存储：

```c
static HashTable *META_TABLE;

void init_meta() {
    META_TABLE = new_hash_table();
}

void set_meta(Meta *meta) {
    hash_set(META_TABLE, meta->name, meta);
}

Meta *get_met(char *name) {
    return hash_get(META_TABLE, name);
}
```

注意，这里的`META_TABLE`实际上是全局的，以后我们要改为局部的。

接下来，就可以在`parser`里收集和计算定量的元信息了。

元信息收集可以与语法解析同时进行，也可以等语法收集完毕之后，再遍历整个语法树，单独收集一道。

出于简便考虑，我先用第一种方法。

最简单的收集点，就是在`let`函数中，刚解析完一个`let`表达式，即将返回之际。

我们在这里插入一个元信息收集的逻辑：

```c
static Node *let(Parser *parser) {
    // ...
    // 解析let语句的expr

    // 收集元信息
    do_meta(parser, expr);
    return expr;
}
```

`do_meta`里可以收集各类数据的元信息，不过我们现在只需要处理定量`let`这一种。

```c
static void do_meta(Parser *parser, Node *expr) {
    // 现在只需要收集定量`let`的元信息
    Meta *m = new_meta(expr);
    m->name = expr->as.asn.name->as.str;
    m->kind = MT_LET;
    m->node = expr;
    set_meta(m);
}
```

具体的统计信息，包括定量的偏移值，放在`set_meta`里计算：

```c
static int cur_seq = 0;
static int cur_offset = 0;

void set_meta(Meta *meta) {
    // 进行统计
    int size = SIZE_INT; // 现在只有int类型，它的尺寸是4字节
    cur_offset += size;
    meta->offset = cur_offset;
    meta->seq = cur_seq++;

    // 存入哈希表
    hash_set(META_TABLE, meta->name, meta);
}
```


